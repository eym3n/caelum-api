from __future__ import annotations

import asyncio
from pathlib import Path
from typing import Any, Dict, List, Tuple

from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

from app.agent.prompts.codegen import PAGE_CODEGEN_PROMPT, LAYOUT_CODEGEN_PROMPT
from app.agent.state import BuilderState
from app.agent.tools.files import get_session_dir
from app.utils.jobs import log_job_event
from toon import encode


class PageCodeOutput(BaseModel):
    code: str = Field(..., description="Complete source for src/app/page.tsx")
    summary: str | None = Field(
        default=None, description="Brief description of page assembly updates"
    )


class LayoutCodeOutput(BaseModel):
    code: str = Field(..., description="Complete source for src/app/layout.tsx")
    summary: str | None = Field(
        default=None, description="Brief description of layout configuration updates"
    )


def _normalize_filename(value: str | None) -> str:
    return value.lstrip("./") if value else ""


def _resolve_component_order(
    design_guidelines: Dict[str, Any],
    generated_sections: List[Dict[str, Any]],
) -> List[Dict[str, str]]:
    generated_map = {
        _normalize_filename(section.get("filename")): section
        for section in generated_sections
        if section.get("component_name")
    }

    ordered: List[Dict[str, str]] = []
    guideline_sections = design_guidelines.get("sections") or []
    if isinstance(guideline_sections, list):
        for entry in guideline_sections:
            if not isinstance(entry, dict):
                continue
            filename = _normalize_filename(
                entry.get("section_file_name_tsx") or entry.get("section_file_name")
            )
            if filename in generated_map:
                ordered.append(
                    {
                        "filename": filename,
                        "component_name": generated_map[filename]["component_name"],
                    }
                )

    for section in generated_sections:
        filename = _normalize_filename(section.get("filename"))
        if filename and not any(item["filename"] == filename for item in ordered):
            ordered.append(
                {
                    "filename": filename,
                    "component_name": section["component_name"],
                }
            )

    return ordered


def _build_page_tsx(component_entries: List[Dict[str, str]]) -> str:
    if component_entries:
        imports = ",\n  ".join(entry["component_name"] for entry in component_entries)
        invocations = "\n      ".join(
            f"<{entry['component_name']} />" for entry in component_entries
        )
        import_block = (
            "import {\n  " + imports + '\n} from "@/components/sections";\n\n'
        )
    else:
        import_block = ""
        invocations = ""

    return (
        import_block + "export default function Page() {\n"
        "  return (\n"
        '    <main className="flex flex-col">\n'
        + (f"      {invocations}\n" if invocations else "")
        + "    </main>\n"
        "  );\n"
        "}\n"
    )


def _build_layout_tsx(design_guidelines: Dict[str, Any]) -> str:
    title = design_guidelines.get("page_title") or "Generated Landing Page"
    description = (
        design_guidelines.get("page_description")
        or "Landing page generated by the LangGraph builder."
    )
    theme = (design_guidelines.get("theme") or "dark").lower()
    if theme == "light":
        body_class = "bg-white text-slate-900"
    else:
        body_class = "bg-slate-950 text-white"

    return (
        'import "./globals.css";\n'
        'import type { Metadata } from "next";\n'
        'import React from "react";\n\n'
        f'export const metadata: Metadata = {{\n  title: "{title}",\n  description: "{description}",\n}};\n\n'
        "export default function RootLayout({ children }: { children: React.ReactNode }) {\n"
        "  return (\n"
        '    <html lang="en">\n'
        f'      <body className="{body_class} antialiased">{{children}}</body>\n'
        "    </html>\n"
        "  );\n"
        "}\n"
    )


def _deterministic_codegen(
    design_guidelines: Dict[str, Any],
    generated_sections: List[Dict[str, Any]],
) -> Dict[str, str]:
    ordered_components = _resolve_component_order(design_guidelines, generated_sections)
    page_code = _build_page_tsx(ordered_components)
    layout_code = _build_layout_tsx(design_guidelines)
    summary = (
        "Fell back to deterministic page/layout assembly "
        f"with {len(ordered_components)} section reference(s)."
    )
    return {
        "page_code": page_code,
        "layout_code": layout_code,
        "summary": summary,
    }


def _build_page_messages(
    design_guidelines: Dict[str, Any],
    generated_sections: List[Dict[str, Any]],
    init_payload: Dict[str, Any],
) -> List:
    guideline_text = encode(design_guidelines)
    payload_text = encode(init_payload)

    sections_payload: List[Dict[str, str]] = []
    for section in generated_sections:
        filename = _normalize_filename(section.get("filename"))
        component_name = section.get("component_name")
        if filename and component_name:
            sections_payload.append(
                {
                    "filename": filename,
                    "component_name": component_name,
                }
            )

    sections_text = encode(sections_payload)

    human_content = (
        "You must assemble the landing page component using the generated sections.\n\n"
        "### Design Guidelines (JSON encoded)\n"
        f"{guideline_text}\n\n"
        "### Generated Section Map (JSON encoded)\n"
        f"{sections_text}\n\n"
        "### Initialization Payload (JSON encoded)\n"
        f"{payload_text}\n\n"
        "Return only the JSON object matching the schema."
    )

    return [
        SystemMessage(content=PAGE_CODEGEN_PROMPT.strip()),
        HumanMessage(content=human_content),
    ]


def _build_layout_messages(
    design_guidelines: Dict[str, Any],
    generated_sections: List[Dict[str, Any]],
    init_payload: Dict[str, Any],
) -> List:
    guideline_text = encode(design_guidelines)
    payload_text = encode(init_payload)
    sections_text = encode(generated_sections)

    human_content = (
        "You must implement the RootLayout according to the design guidelines and init payload.\n\n"
        "### Design Guidelines (JSON encoded)\n"
        f"{guideline_text}\n\n"
        "### Generated Sections (JSON encoded)\n"
        f"{sections_text}\n\n"
        "### Initialization Payload (JSON encoded)\n"
        f"{payload_text}\n\n"
        "Return only the JSON object matching the schema."
    )

    return [
        SystemMessage(content=LAYOUT_CODEGEN_PROMPT.strip()),
        HumanMessage(content=human_content),
    ]


async def _generate_page_code(
    design_guidelines: Dict[str, Any],
    generated_sections: List[Dict[str, Any]],
    init_payload: Dict[str, Any],
) -> PageCodeOutput:
    messages = _build_page_messages(design_guidelines, generated_sections, init_payload)
    model = ChatOpenAI(model="gpt-5", reasoning_effort="minimal")
    structured_llm = model.with_structured_output(PageCodeOutput)

    last_exc: Exception | None = None
    for attempt in range(1, 10):
        try:
            result = await structured_llm.ainvoke(messages)
            print(f"[CODEGEN] Page worker completed attempt {attempt}")
            if result is None:
                print(
                    f"[CODEGEN] Page worker result is None for {attempt}, retrying..."
                )
                continue

            return result
        except Exception as exc:  # pragma: no cover - logging
            last_exc = exc
            print(f"[CODEGEN] Page worker attempt {attempt} failed: {exc}")
    raise RuntimeError("Page code generation failed after 3 attempts.") from last_exc


async def _generate_layout_code(
    design_guidelines: Dict[str, Any],
    generated_sections: List[Dict[str, Any]],
    init_payload: Dict[str, Any],
) -> LayoutCodeOutput:
    messages = _build_layout_messages(
        design_guidelines, generated_sections, init_payload
    )
    model = ChatOpenAI(model="gpt-5", reasoning_effort="minimal")
    structured_llm = model.with_structured_output(LayoutCodeOutput)

    last_exc: Exception | None = None
    for attempt in range(1, 10):
        try:
            result = await structured_llm.ainvoke(messages)
            print(f"[CODEGEN] Layout worker completed attempt {attempt}")
            if result is None:
                print(
                    f"[CODEGEN] Layout worker result is None for {attempt}, retrying..."
                )
                continue

            return result

        except Exception as exc:  # pragma: no cover - logging
            last_exc = exc
            print(f"[CODEGEN] Layout worker attempt {attempt} failed: {exc}")
    raise RuntimeError("Layout code generation failed after 3 attempts.") from last_exc


def codegen(state: BuilderState) -> BuilderState:
    log_job_event(
        state.job_id,
        node="codegen",
        message="Authoring page.tsx and layout.tsx...",
        event_type="node_started",
    )

    try:
        design_guidelines = state.design_guidelines or {}
        generated_sections = state.generated_sections or []
        init_payload = state.init_payload or {}

        if not generated_sections:
            log_job_event(
                state.job_id,
                node="codegen",
                message="No generated sections found; skipping codegen.",
                event_type="node_completed",
            )
            print("[CODEGEN] Skipping codegen because no sections were generated.")
            return {
                "codegen_summary": "No sections generated; skipping page/layout updates.",
            }

        print(
            f"[CODEGEN] Launching page/layout workers for session {state.session_id} with {len(generated_sections)} sections."
        )

        async def run_workers() -> Tuple[PageCodeOutput, LayoutCodeOutput]:
            page_task = asyncio.create_task(
                _generate_page_code(design_guidelines, generated_sections, init_payload)
            )
            await asyncio.sleep(1)
            layout_task = asyncio.create_task(
                _generate_layout_code(
                    design_guidelines, generated_sections, init_payload
                )
            )
            page_result, layout_result = await asyncio.gather(page_task, layout_task)
            return page_result, layout_result

        def execute_workers() -> Tuple[PageCodeOutput, LayoutCodeOutput]:
            try:
                return asyncio.run(run_workers())
            except RuntimeError:
                loop = asyncio.new_event_loop()
                try:
                    asyncio.set_event_loop(loop)
                    return loop.run_until_complete(run_workers())
                finally:
                    asyncio.set_event_loop(None)
                    loop.close()

        try:
            page_result, layout_result = execute_workers()
        except Exception as worker_exc:
            print(
                f"[CODEGEN] Page/layout workers failed ({worker_exc}); using deterministic fallback."
            )
            response_data = _deterministic_codegen(
                design_guidelines, generated_sections
            )
        else:
            response_data = {
                "page_code": page_result.code if page_result else "",
                "layout_code": layout_result.code if layout_result else "",
                "summary": " | ".join(
                    filter(
                        None,
                        [
                            page_result.summary if page_result else None,
                            layout_result.summary if layout_result else None,
                        ],
                    )
                )
                or "Generated page.tsx and layout.tsx via LLM workers.",
            }

        session_dir = get_session_dir(state.session_id)
        page_path = session_dir / "src" / "app" / "page.tsx"
        layout_path = session_dir / "src" / "app" / "layout.tsx"

        page_path.parent.mkdir(parents=True, exist_ok=True)
        layout_path.parent.mkdir(parents=True, exist_ok=True)

        if not response_data["page_code"] or not response_data["layout_code"]:
            print(
                "[CODEGEN] LLM produced empty output; falling back to deterministic builder."
            )
            response_data = _deterministic_codegen(
                design_guidelines, generated_sections
            )

        page_content = response_data["page_code"].rstrip()
        layout_content = response_data["layout_code"].rstrip()
        if not page_content.endswith("\n"):
            page_content += "\n"
        if not layout_content.endswith("\n"):
            layout_content += "\n"

        page_path.write_text(page_content, encoding="utf-8")
        layout_path.write_text(layout_content, encoding="utf-8")
        print(f"[CODEGEN] Wrote page.tsx to {page_path}")
        print(f"[CODEGEN] Wrote layout.tsx to {layout_path}")

        summary = response_data["summary"]
        log_job_event(
            state.job_id,
            node="codegen",
            message=summary,
            event_type="node_completed",
            data={
                "page_path": str(page_path),
                "layout_path": str(layout_path),
            },
        )
        print(f"[CODEGEN] Completed successfully: {summary}")

        return {
            "codegen_summary": summary,
        }

    except Exception as exc:
        error_message = f"Codegen node failed: {exc}"
        print(f"[CODEGEN] {error_message}")
        log_job_event(
            state.job_id,
            node="codegen",
            message=error_message,
            event_type="error",
            data={"error": str(exc)},
        )
        raise
